{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs: \n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2018.4.16          |           py36_0         142 KB  conda-forge\n",
      "    mako-1.0.7                 |           py36_0         115 KB  conda-forge\n",
      "    keras-2.1.6                |           py36_0         500 KB  conda-forge\n",
      "    mock-2.0.0                 |           py36_0         103 KB  conda-forge\n",
      "    theano-1.0.2               |           py36_0         3.7 MB  conda-forge\n",
      "    libprotobuf-3.5.2          |       hd28b015_1         4.5 MB  conda-forge\n",
      "    pygpu-0.7.6                |           py36_0         1.4 MB  conda-forge\n",
      "    tensorflow-1.1.0           |           py36_0        25.3 MB  conda-forge\n",
      "    pbr-4.1.0                  |             py_0          61 KB  conda-forge\n",
      "    libgpuarray-0.7.6          |                0         249 KB  conda-forge\n",
      "    conda-4.5.6                |           py36_0         623 KB  conda-forge\n",
      "    protobuf-3.5.2             |           py36_0         1.4 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        38.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    keras:       2.1.6-py36_0     conda-forge\n",
      "    libgpuarray: 0.7.6-0          conda-forge\n",
      "    libprotobuf: 3.5.2-hd28b015_1 conda-forge\n",
      "    mako:        1.0.7-py36_0     conda-forge\n",
      "    mock:        2.0.0-py36_0     conda-forge\n",
      "    pbr:         4.1.0-py_0       conda-forge\n",
      "    protobuf:    3.5.2-py36_0     conda-forge\n",
      "    pygpu:       0.7.6-py36_0     conda-forge\n",
      "    tensorflow:  1.1.0-py36_0     conda-forge\n",
      "    theano:      1.0.2-py36_0     conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi:     2018.4.16-py36_0             --> 2018.4.16-py36_0 conda-forge\n",
      "    conda:       4.5.5-py36_0                 --> 4.5.6-py36_0     conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2018.4.16    |  142 KB | ####################################### | 100% \n",
      "mako-1.0.7           |  115 KB | ####################################### | 100% \n",
      "keras-2.1.6          |  500 KB | ####################################### | 100% \n",
      "mock-2.0.0           |  103 KB | ####################################### | 100% \n",
      "theano-1.0.2         |  3.7 MB | ####################################### | 100% \n",
      "libprotobuf-3.5.2    |  4.5 MB | ####################################### | 100% \n",
      "pygpu-0.7.6          |  1.4 MB | ####################################### | 100% \n",
      "tensorflow-1.1.0     | 25.3 MB | ####################################### | 100% \n",
      "pbr-4.1.0            |   61 KB | ####################################### | 100% \n",
      "libgpuarray-0.7.6    |  249 KB | ####################################### | 100% \n",
      "conda-4.5.6          |  623 KB | ####################################### | 100% \n",
      "protobuf-3.5.2       |  1.4 MB | ####################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 3.6MB/s \n",
      "\u001b[?25hRequirement not upgraded as not directly required: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement not upgraded as not directly required: h5py in /opt/conda/lib/python3.6/site-packages (from keras) (2.7.1)\n",
      "Collecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Requirement not upgraded as not directly required: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement not upgraded as not directly required: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras) (1.14.3)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 5.5MB/s \n",
      "\u001b[?25hRequirement not upgraded as not directly required: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "  Found existing installation: Keras 2.1.6\n",
      "    Uninstalling Keras-2.1.6:\n",
      "      Successfully uninstalled Keras-2.1.6\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 49.1MB 792kB/s \n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/13/b05bbd05d9f0c19e5746f149a285aa81f7c353e231ffecdb237c6e2ad3cc/grpcio-1.13.0-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.1MB 3.2MB/s \n",
      "\u001b[?25hRequirement not upgraded as not directly required: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement not upgraded as not directly required: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.5.2)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/8d/6664518f9b6ced0aa41cf50b989740909261d4c212557400c48e5cda0804/absl-py-0.2.2.tar.gz (82kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 10.4MB/s \n",
      "\u001b[?25hRequirement not upgraded as not directly required: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.14.3)\n",
      "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 8.4MB/s \n",
      "\u001b[?25hRequirement not upgraded as not directly required: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement not upgraded as not directly required: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow) (39.1.0)\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 10.3MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 9.9MB/s \n",
      "\u001b[?25hCollecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Requirement not upgraded as not directly required: werkzeug>=0.11.10 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow) (0.14.1)\n",
      "Building wheels for collected packages: absl-py, gast, termcolor, html5lib\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a0/f8/e9/1933dbb3447ea6ef57062fd5461cb118deb8c2ed074e8344bf\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built absl-py gast termcolor html5lib\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: grpcio, astor, absl-py, html5lib, markdown, bleach, tensorboard, gast, termcolor, tensorflow\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 2.1.3\n",
      "    Uninstalling bleach-2.1.3:\n",
      "      Successfully uninstalled bleach-2.1.3\n",
      "  Found existing installation: tensorflow 1.1.0\n",
      "    Uninstalling tensorflow-1.1.0:\n",
      "      Successfully uninstalled tensorflow-1.1.0\n",
      "Successfully installed absl-py-0.2.2 astor-0.7.1 bleach-1.5.0 gast-0.2.0 grpcio-1.13.0 html5lib-0.9999999 markdown-2.6.11 tensorboard-1.8.0 tensorflow-1.8.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! conda install -c conda-forge keras  -y\n",
    "!pip install --upgrade keras\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train, Y_train = load_fashion_mnist(\"./fashionmnist/\", kind = 'train')\n",
    "X_test, Y_test = load_fashion_mnist(\"./fashionmnist/\", kind = 't10k')\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.2066425708591938\n",
      "Test accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Pullover\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = 24\n",
    "plt.imshow(X_train[x].reshape((28,28)), cmap=\"gist_gray\")\n",
    "plt.show()\n",
    "prediction = model.predict_classes(np.expand_dims(X_test[x], axis=0))\n",
    "print(\"Predicted label: \"+ labels[prediction[0]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:\"T-shirt/top\",\n",
    "          1:\"Trouser\",\n",
    "          2:\"Pullover\",\n",
    "          3:\"Dress\",\n",
    "          4:\"Coat\",\n",
    "          5:\"Sandal\",\n",
    "          6:\"Shirt\",\n",
    "          7:\"Sneaker\",\n",
    "          8:\"Bag\",\n",
    "          9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.2274776839196682\n",
      "Test accuracy: 0.9172\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.23620292901694775\n",
      "Test accuracy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.22314709869921207\n",
      "Test accuracy: 0.9216\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.22979537236392497\n",
      "Test accuracy: 0.9239\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.2068316811054945\n",
      "Test accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.21299948731660842\n",
      "Test accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.23349117990732193\n",
      "Test accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: 0.22861582611203193\n",
      "Test accuracy: 0.9186\n"
     ]
    }
   ],
   "source": [
    "batch_size = 600\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Test loss: nan\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='relu'))\n",
    "print(\"Starting...\")\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
